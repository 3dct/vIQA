{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Test Metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72951f718eb4c97e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import and Configuration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7df78e46239d75d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-04T10:19:04.546981100Z",
     "start_time": "2024-01-04T10:19:04.292317Z"
    }
   },
   "outputs": [],
   "source": [
    "import psnr, rmse, vif, fsim, ssim, msssim, vsi\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "from skimage.color import rgb2gray\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "file_path_img_r = '../../TID2013/reference_images/I01.bmp'\n",
    "file_path_img_m = '../../TID2013/distorted_images/I01_01_2.bmp'\n",
    "\n",
    "img_r = io.imread(file_path_img_r)\n",
    "img_m = io.imread(file_path_img_m)\n",
    "\n",
    "img_r_gray = rgb2gray(img_r)\n",
    "img_m_gray = rgb2gray(img_m)\n",
    "\n",
    "img_r_tensor = torch.tensor(img_r).permute(2, 0, 1).unsqueeze(0)\n",
    "img_m_tensor = torch.tensor(img_m).permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "img_r_tensor_gray = torchvision.transforms.Grayscale()(img_r_tensor)\n",
    "img_m_tensor_gray = torchvision.transforms.Grayscale()(img_m_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T10:22:12.407188300Z",
     "start_time": "2024-01-04T10:22:12.001159900Z"
    }
   },
   "id": "6595dca8a766d911"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(384, 512, 3)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_r.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T10:19:19.650785500Z",
     "start_time": "2024-01-04T10:19:19.645796400Z"
    }
   },
   "id": "6b63e15167090951"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3, 384, 512])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_r_tensor.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T10:19:21.670826800Z",
     "start_time": "2024-01-04T10:19:21.665696800Z"
    }
   },
   "id": "6ae8efba6c984b6d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea11f7f44be3a14a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PSNR"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3109533afe89c5ea"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "30.07379483937222"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = psnr.PSNR(data_range=255, normalize=False, batch=False)\n",
    "metric.score(img_r, img_m)\n",
    "metric.score_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:35:15.672728200Z",
     "start_time": "2024-01-03T17:35:15.618918200Z"
    }
   },
   "id": "3c4e8fab6649a47f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "--> code OK, value OK"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30dd49144bbbe4ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RMSE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d49acb164d6ba5e"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "7.995588569810916"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = rmse.RMSE(data_range=255, normalize=False)\n",
    "metric.score(img_r, img_m)\n",
    "metric.score_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:35:15.673725400Z",
     "start_time": "2024-01-03T17:35:15.630259200Z"
    }
   },
   "id": "a7402f9753e570f9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "--> code OK, value probably OK"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7689fc6dcbd9617d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### VIFp"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe9c7f748256af0e"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m metric \u001B[38;5;241m=\u001B[39m vif\u001B[38;5;241m.\u001B[39mVIFp(data_range\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m255\u001B[39m, normalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, chromatic\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m----> 2\u001B[0m metric\u001B[38;5;241m.\u001B[39mscore(img_r_gray, img_m_gray)\n\u001B[0;32m      3\u001B[0m metric\u001B[38;5;241m.\u001B[39mscore_val\n",
      "File \u001B[1;32mZ:\\CT-Student\\LBehammer\\IQA_Library\\vif.py:39\u001B[0m, in \u001B[0;36mVIFp.score\u001B[1;34m(self, img_r, img_m, **kwargs)\u001B[0m\n\u001B[0;32m     37\u001B[0m     img_m_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(img_m)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 39\u001B[0m     img_r_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(img_r)\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     40\u001B[0m     img_m_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(img_m)\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     42\u001B[0m score_val \u001B[38;5;241m=\u001B[39m vif_p(img_r_tensor, img_m_tensor, data_range\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parameters[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata_range\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3"
     ]
    }
   ],
   "source": [
    "metric = vif.VIFp(data_range=255, normalize=False, chromatic=True)\n",
    "metric.score(img_r, img_m)\n",
    "metric.score_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T12:00:16.292427600Z",
     "start_time": "2024-01-04T12:00:16.182048400Z"
    }
   },
   "id": "d317b893da3bab89"
  },
  {
   "cell_type": "markdown",
   "source": [
    "--> code OK, value **NOT** OK"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5644b0b928e51097"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9983500921124459\n",
      "tensor(0.6078)\n",
      "0.9075681824869333\n"
     ]
    }
   ],
   "source": [
    "# sewar VIFp\n",
    "from sewar import vifp\n",
    "print(vifp(img_r_gray, img_m_gray, sigma_nsq=3.2))\n",
    "\n",
    "# piq VIFp\n",
    "from piq import vif_p as piq_vif_p\n",
    "print(piq_vif_p(img_r_tensor_gray, img_m_tensor_gray, data_range=255, sigma_n_sq=3.2))\n",
    "\n",
    "# xdesign VIFp\n",
    "from xdesign.metrics.fullref import vifp as xdesign_vifp\n",
    "print(xdesign_vifp(img_m_gray, img_r_gray, L =255)[1].mean())\n",
    "\n",
    "# # IQA-pytorch VIFp\n",
    "# from IQA_pytorch import VIF\n",
    "# from torch.nn.functional import normalize\n",
    "# metric = VIF()\n",
    "# score = metric(normalize(img_r_tensor.float()), normalize(img_m_tensor.float()), as_loss=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T12:01:11.672682300Z",
     "start_time": "2024-01-04T12:01:10.939151Z"
    }
   },
   "id": "570b872c6104b3d0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### FSIM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1e8bee96d7208b3"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9878281950950623"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_fsim_m = fsim.FSIM(data_range=255, normalize=False, chromatic=True)\n",
    "metric_fsim_m.score(img_r, img_m)\n",
    "metric_fsim_m.score_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:35:17.694509800Z",
     "start_time": "2024-01-03T17:35:17.615163900Z"
    }
   },
   "id": "b2323034962dbec8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "--> code OK, value OK"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f83fe954ff5c16e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SSIM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba894bf6b972866d"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8574712126318319"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_ssim_m = ssim.SSIM(data_range=255, normalize=False)\n",
    "metric_ssim_m.score(img_r, img_m, gaussian_weights=True, use_sample_covariance=False, sigma=1.5, channel_axis=2)\n",
    "metric_ssim_m.score_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:35:17.782274300Z",
     "start_time": "2024-01-03T17:35:17.690519700Z"
    }
   },
   "id": "85dc8402092d712"
  },
  {
   "cell_type": "markdown",
   "source": [
    "--> code OK, value **NOT** OK"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80849a3ebb71206b"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sewar:  (0.8909138757539132, 0.8909517569398758)\n",
      "piq:  tensor(0.9807)\n",
      "skimage:  0.8574712126318319\n",
      "pytorch_msssim:  tensor(1.)\n",
      "pytorch-ignite:  0.921117043856763\n",
      "xdesign:  0.9999465399884802\n",
      "IQA-pytorch:  tensor([0.9990])\n"
     ]
    }
   ],
   "source": [
    "# sewar ssim\n",
    "from sewar import ssim\n",
    "print('sewar: ', ssim(img_r, img_m))\n",
    "\n",
    "# piq ssim\n",
    "from piq import ssim as piq_ssim\n",
    "print('piq: ', piq_ssim(img_r_tensor_gray, img_m_tensor_gray, data_range=255))\n",
    "\n",
    "# skimage ssim\n",
    "from skimage.metrics import structural_similarity as skimage_ssim\n",
    "print('skimage: ', skimage_ssim(img_r, img_m, data_range=255, gaussian_weights=True, use_sample_covariance=False, sigma=1.5, channel_axis=2))\n",
    "\n",
    "# pytorch-msssim ssim\n",
    "from pytorch_msssim import ssim as pytorch_msssim_ssim\n",
    "print('pytorch_msssim: ', pytorch_msssim_ssim(img_r_tensor_gray, img_m_tensor_gray, data_range=255))\n",
    "\n",
    "# pytorch-ignite ssim\n",
    "from ignite.metrics import SSIM\n",
    "metric = SSIM(data_range=255)\n",
    "metric.update((img_r_tensor_gray, img_m_tensor_gray))\n",
    "print('pytorch-ignite: ', metric.compute())\n",
    "\n",
    "# xdesign ssim\n",
    "from xdesign.metrics import ssim as xdesign_ssim\n",
    "print('xdesign: ', xdesign_ssim(img_r_gray, img_m_gray, L=255)[1])\n",
    "\n",
    "# IQA-pytorch ssim\n",
    "from IQA_pytorch import SSIM\n",
    "from torch.nn.functional import normalize\n",
    "metric = SSIM()\n",
    "print('IQA-pytorch: ', metric(normalize(img_r_tensor_gray.float()), normalize(img_m_tensor_gray.float()), as_loss=False))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T10:22:43.181968800Z",
     "start_time": "2024-01-04T10:22:41.699267300Z"
    }
   },
   "id": "4f5c7f6ff49805e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MSSSIM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b6e089adf5fcadc"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.9821697985210762+0j)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_msssim_m = msssim.MSSSIM(data_range=255, normalize=False)\n",
    "metric_msssim_m.score(img_r, img_m)\n",
    "metric_msssim_m.score_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:35:19.674895600Z",
     "start_time": "2024-01-03T17:35:18.771324800Z"
    }
   },
   "id": "d4c469ad91d3af61"
  },
  {
   "cell_type": "markdown",
   "source": [
    "--> code OK, value **NOT** OK"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78ce227c78498e07"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9821697985210762+0j)\n",
      "tensor(0.9775)\n",
      "0.999975820750989\n",
      "tensor([0.8833])\n"
     ]
    }
   ],
   "source": [
    "# sewar msssim\n",
    "from sewar import msssim\n",
    "print(msssim(img_r, img_m))\n",
    "\n",
    "# piq msssim\n",
    "from piq import multi_scale_ssim as piq_msssim\n",
    "print(piq_msssim(img_r_tensor, img_m_tensor, data_range=255))\n",
    "\n",
    "# pytorch-msssim msssim\n",
    "try:\n",
    "    from pytorch_msssim import ms_ssim as pytorch_msssim_msssim\n",
    "    print(pytorch_msssim_msssim(img_r_tensor, img_m_tensor, data_range=255))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# xdesign msssim\n",
    "from xdesign.metrics import msssim as xdesign_msssim\n",
    "print(xdesign_msssim(img_r_gray, img_m_gray, L=255)[1])\n",
    "\n",
    "# IQA-pytorch msssim\n",
    "from IQA_pytorch import MS_SSIM\n",
    "from torch.nn.functional import normalize\n",
    "metric = MS_SSIM()\n",
    "print(metric(normalize(img_r_tensor.float()), normalize(img_m_tensor.float()), as_loss=False))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:35:20.773696900Z",
     "start_time": "2024-01-03T17:35:19.675865900Z"
    }
   },
   "id": "dd02529373b938b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### VSI"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "279bb24dd0e3d431"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9948647022247314"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = vsi.VSI(data_range=255, normalize=False)\n",
    "metric.score(img_r, img_m)\n",
    "metric.score_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:35:20.821656Z",
     "start_time": "2024-01-03T17:35:20.773696900Z"
    }
   },
   "id": "6009b315234a0435"
  },
  {
   "cell_type": "markdown",
   "source": [
    "--> code OK, value OK"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9334ba690cf03b36"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "| Metric | Code OK | Value OK   |\n",
    "| --- |---------|------------|\n",
    "| PSNR | OK      | OK         |\n",
    "| RMSE | OK      | OK         |\n",
    "| VIFp | OK      | **NOT** OK |\n",
    "| FSIM | OK      | OK         |\n",
    "| SSIM | OK      | **NOT** OK |\n",
    "| MSSSIM | OK      | **NOT** OK |\n",
    "| VSI | OK      | OK         |\n",
    "| MAD | --      | --         |\n",
    "| GSM | --      | --         |\n",
    "| SFF | --      | --         |\n",
    "| CNR | --      | --         |\n",
    "| Ma | --      | --         |\n",
    "| PI | --      | --         |\n",
    "| NIQE | --      | --         |"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b32811577a434e51"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
